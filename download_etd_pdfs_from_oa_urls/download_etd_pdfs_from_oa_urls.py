import os
import csv
import argparse
import requests
from requests.packages.urllib3.exceptions import InsecureRequestWarning

# Suppress InsecureRequestWarning for unverified HTTPS requests to allow unverified requests
# from self-signed certificates from some repository instances.
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)


def setup_arg_parser():
    parser = argparse.ArgumentParser(
        description="Download PDFs from a CSV file generated by OpenAlex script.")
    parser.add_argument("-i", "--input", required=True,
                        help="Path to the input CSV file (must contain 'work_id' and 'oa_url').")
    parser.add_argument(
        "-o", "--output", help="Path to the output log CSV file. Defaults to '[input_filename_full]_downloads_log.csv'.")
    parser.add_argument(
        "-d", "--directory", help="Directory to save downloaded PDF files. Defaults to '[input_filename_full]_pdfs/'.")
    return parser


def extract_filename_from_work_id(work_id_url):
    if not work_id_url or not isinstance(work_id_url, str):
        return None
    try:
        name_part = work_id_url.strip().split('/')[-1]
        if name_part.startswith('W') and name_part[1:].isdigit():
            return f"{name_part}.pdf"
    except Exception:
        pass
    return None


def check_url(url_to_check):
    if not url_to_check or not url_to_check.startswith(('http://', 'https://')):
        return False, False, "Invalid or empty URL"
    try:
        response = requests.head(
            url_to_check, timeout=15, allow_redirects=True, verify=False)
        if response.ok:
            content_type = response.headers.get('Content-Type', '').lower()
            is_pdf = 'application/pdf' in content_type
            return True, is_pdf, content_type if not is_pdf else None
        else:
            return False, False, f"HTTP Status: {response.status_code}"
    except requests.exceptions.Timeout:
        return False, False, "Request timed out"
    except requests.exceptions.RequestException as e:
        return False, False, str(e)


def download_pdf_file(url, full_filepath):
    try:
        response = requests.get(
            url, stream=True, timeout=30, verify=False, allow_redirects=True)
        if response.ok:
            with open(full_filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            return True, None
        else:
            return False, f"Download HTTP Status: {response.status_code}"
    except requests.exceptions.Timeout:
        return False, "Download timed out"
    except requests.exceptions.RequestException as e:
        return False, f"Download error: {str(e)}"


def process_csv_for_downloads(input_filepath, output_filepath, download_dir):
    if not os.path.exists(download_dir):
        try:
            os.makedirs(download_dir)
            print(f"Created download directory: {download_dir}")
        except OSError as e:
            print(f"Error creating download directory {download_dir}: {e}")
            return

    processed_count = 0
    download_success_count = 0

    try:
        with open(input_filepath, 'r', encoding='utf-8-sig') as infile, \
                open(output_filepath, 'w', encoding='utf-8') as outfile:

            reader = csv.DictReader(infile)
            if not reader.fieldnames or 'work_id' not in reader.fieldnames or 'oa_url' not in reader.fieldnames:
                print("Error: Input CSV must contain 'work_id' and 'oa_url' columns.")
                return

            new_fieldnames = list(reader.fieldnames) + \
                ['pdf_filename_generated', 'url_resolves', 'is_pdf_content_type',
                 'download_attempted', 'download_success', 'saved_pdf_path', 'processing_notes']
            writer = csv.DictWriter(outfile, fieldnames=new_fieldnames)
            writer.writeheader()

            print(f"Processing input file: {input_filepath}")
            print(f"Output log will be written to: {output_filepath}")
            print(f"PDFs will be attempted to download to: {download_dir}")

            for i, row in enumerate(reader):
                processed_count += 1
                print(f"\nProcessing row {i+1}...")
                output_row = {fieldname: row.get(
                    fieldname, '') for fieldname in reader.fieldnames}

                work_id = row.get('work_id', '').strip()
                oa_url = row.get('oa_url', '').strip()

                output_row['pdf_filename_generated'] = ''
                output_row['url_resolves'] = False
                output_row['is_pdf_content_type'] = False
                output_row['download_attempted'] = False
                output_row['download_success'] = False
                output_row['saved_pdf_path'] = ''
                output_row['processing_notes'] = ''

                if not oa_url:
                    print("  No oa_url found in row.")
                    output_row['processing_notes'] = "No oa_url provided."
                    writer.writerow(output_row)
                    continue

                print(f"  Work ID: {work_id}, OA URL: {oa_url}")

                generated_filename = extract_filename_from_work_id(work_id)
                output_row['pdf_filename_generated'] = generated_filename if generated_filename else ''

                if not generated_filename:
                    print(f"  Could not generate a valid PDF filename from work_id: {work_id}")
                    output_row['processing_notes'] = "Could not generate PDF filename from work_id."
                    writer.writerow(output_row)
                    continue

                resolves, is_pdf_type, check_err_msg = check_url(oa_url)
                output_row['url_resolves'] = resolves
                output_row['is_pdf_content_type'] = is_pdf_type

                if not resolves:
                    print(f"  URL did not resolve or error: {check_err_msg}")
                    output_row['processing_notes'] = f"URL check failed: {check_err_msg}"
                elif not is_pdf_type:
                    print(f"  URL resolved but content-type is not PDF. Content-Type: {check_err_msg if check_err_msg else 'Unknown'}")
                    output_row['processing_notes'] = f"Not a PDF by Content-Type: {check_err_msg if check_err_msg else 'N/A'}"
                else:
                    print("  URL resolved and content-type indicates PDF.")
                    output_row['download_attempted'] = True
                    pdf_save_path = os.path.join(
                        download_dir, generated_filename)
                    output_row['saved_pdf_path'] = pdf_save_path

                    print(f"  Attempting to download to: {pdf_save_path}")
                    downloaded, dl_err_msg = download_pdf_file(
                        oa_url, pdf_save_path)

                    if downloaded:
                        output_row['download_success'] = True
                        download_success_count += 1
                        print(f"  Successfully downloaded: {generated_filename}")
                    else:
                        output_row['download_success'] = False
                        output_row['processing_notes'] = f"Download failed: {dl_err_msg}"
                        print(f"  Failed to download: {dl_err_msg}")
                        if os.path.exists(pdf_save_path):
                            try:
                                os.remove(pdf_save_path)
                            except OSError:
                                pass

                writer.writerow(output_row)

            print(f"\nProcessing complete. Processed {processed_count} rows.")
            print(f"Successfully downloaded {download_success_count} PDF files.")

    except FileNotFoundError:
        print(f"Error: Input file not found at {input_filepath}")
    except Exception as e:
        print(f"An unexpected error occurred during CSV processing: {e}")


def main():
    parser = setup_arg_parser()
    args = parser.parse_args()

    input_path = args.input
    output_path_arg = args.output
    download_path_arg = args.directory

    input_file_dir = os.path.dirname(input_path)

    full_input_basename = os.path.basename(input_path)

    if not output_path_arg:
        output_path = os.path.join(input_file_dir, f"{full_input_basename}_downloads_log.csv")
    else:
        output_path = output_path_arg

    if not download_path_arg:
        download_path = os.path.join(input_file_dir, f"{full_input_basename}_pdfs")
    else:
        download_path = download_path_arg

    process_csv_for_downloads(input_path, output_path, download_path)


if __name__ == "__main__":
    main()
